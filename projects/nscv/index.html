<!DOCTYPE html>
<html lang="en">
<head>
    <title>Neuro-Symbolic Visual Reasoning and Program Synthesis</title>
    <meta name="description" content="Neuro-Symbolic Visual Reasoning and Program Synthesis">
    <meta name="keywords" content="Vision,Program Synthesis,Language,Learning,Reasoning,Computer Science">

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-alpha.6/css/bootstrap.min.css" integrity="sha384-rwoIResjU2yc3z8GV/NPeZWAv56rSmLldC3R/AZzGRnGxQQKnKkoFVhFQhNUwEyJ" crossorigin="anonymous">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <!--link rel="shortcut icon" href="static/img/favicon.ico"-->

    <!--[if lt IE 9]>
      <script src="http://cdn.bootcss.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="http://cdn.bootcss.com/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->
    <style type="text/css">
body{font-family:"Open Sans",Segoe,"Segoe UI","Lucida Sans Unicode","Lucida Grande","Avenir","Seravek","Ubuntu","DejaVu Sans","Trebuchet MS",Verdana,Arial,sans-serif}
body{margin:0;padding:0}
#header{background:#fafafa;opacity:0.95;margin:0 auto;padding:50px 0 0;text-align:center;cursor:default;text-align:center}
#header-container{margin:0 auto;padding: 0 2em;max-width:1600px}

#header-container .col-logo{text-align:left}
#header-container .logo{position:relative;z-index:100;height:50px;margin-top:20px;margin-right:10px}

#header-container .col-info{text-align:left;margin-bottom:20px}
#header-container #title{margin:.525em 0;font-size:2.4em;font-weight:500;text-align:center}
#header-container .subtitle{color:#333333; font-size:20px; text-align:center; font-weight:normal}
#header-container .datetime{color:#BB2222; font-size:20px; text-align:center; font-weight:normal}

.paper-info{display:inline-block;margin:0 auto;text-align:left}
.paper-info-margin{margin-bottom:20px}
.paper-info p, .paper-info h3{line-height:1.6em; margin-bottom: 0em}
.paper-info .title{font-size:16px;color:#333333;font-weight:600}
.paper-info .authors, .paper-info .authors a{color:#666666}
.paper-info .email{color:#666; font-size:14px}
.paper-info .tag{margin:auto auto;padding:0;list-style:none;text-align:left}
.paper-info .tag li{display:inline-block;margin:auto;padding:0 3px 0 0;line-height:10px}
.paper-info .conference, .paper-info .conference a{color:#BB2222;font-weight:600}

#wave-canvas{display:block;margin:-80px 0 0;width:100%;height:150px}

#content{padding-top:0px;text-align:left}
.content-container{margin:0 auto 10px; padding: 0 2em;max-width:1600px;color:#333333}

.content-container .header{padding:15px 30px 5px;border-bottom:1px solid #dddddd}
.content-container .header .indicator{color:#777777;margin-right:12px}

.content-container .main{background:#ffffff;padding:15px 5px 15px 30px}
.content-container .main .caption{color:#666666}
.content-container .main .bib{color:#666666;font-size:14px;}
.content-container .main .bib pre{margin:0;padding:0;}

.overview{font-size:18px}
.schedule-table th{width:30%}
.reference-list {color: #666666;}
.reference-list .number{min-width:40px;text-align:right;padding-right:10px}
.speakers-list img{width:100%;max-width:150px;}
.organizers-list>div {width:100%;flex-wrap:wrap}
.organizers-list .item {width:200px;margin-right:50px;text-align:left}

#footer{padding:2em 0 0.5em;margin:30px 0 0;background:#ffffff;opacity:0.95;font-size:14px;line-height:12px;text-align:center}
.highlight, .highlight a{color:#BB2222;font-weight:600}
    </style>
</head>
<body>
<div id="main">
    <div id="header">
        <div id="header-container" class="container">
          <div class="row">
            <div class="col-md-12 col-xl-12 col-info">
                <h1 id="title">Neuro-Symbolic Visual Reasoning and Program Synthesis</h1>
                <h4 class="subtitle">CVPR 2020 Tutorial</h4>
                <h4 class="datetime">June 14, 2020&nbsp;&nbsp;9:00 AM - 1:00 PM</h4>
            </div>
          </div>

        </div>
        <canvas id="wave-canvas"></canvas>
    </div>
    <div id="content">
        <div class="content-container container">
            <div class="header"><h4>Overview</h4></div>
            <div class="main overview">
                <p>
                Recent advances in deep learning gave rise to highly expressive models achieving remarkable results on visual perception tasks such as object, action and scene recognition. However, it is widely accepted that in order to develop truly intelligent systems, we need to bridge the gap between perception and cognition. Highly cognitive tasks such as planning, abstracting, reasoning and explaining are typically associated with symbolic systems which do not scale to the complex high-dimensional visual world. The relatively new field of neuro-symbolic computation proposes to combine the strengths of deep models with symbolic approaches, by using the former to learn disentangled, interpretable, low-dimensional representations which significantly reduce the search space for symbolic approaches such as program synthesis (cf. [5,15]). Another reason to study the interplay between neural and symbolic approaches is related to human, and in particular infant, learning. While far from fully understood, there is an increasing body of evidence that similar mechanisms combining low-level perception with high level cognition are at play in the human brain [1,12].
                </p><p>
                This tutorial will bring together researchers from computer vision, graphics, robotics, cognitive science, and developmental psychology to exchange ideas, share recent research results and applications in the emerging field of neuro-symbolic computation, focusing on computer vision.
                </p>
            </div>
        </div>
        <div class="content-container container">
            <div class="header"><h4>Schedule</h4></div>
            <div class="main">
                <table class="schedule-table table table-striped">
                  <tbody>
                    <tr> <th scope="row">9:00 AM - 9:20 AM</th>   <td>Opening Remarks</td> </tr>
                    <tr> <th scope="row">9:20 AM - 9:50 AM</th>   <td>Talk 1 [Topic: TBD]</td> </tr>
                    <tr> <th scope="row">9:50 AM - 10:20 AM</th>  <td>Talk 2 [Topic: TBD]</td> </tr>
                    <tr> <th scope="row">10:20 AM - 10:50 AM</th> <td>Talk 3 [Topic: TBD]</td> </tr>
                    <tr> <th scope="row">10:50 AM - 11:00 AM</th> <td>Break</td> </tr>
                    <tr> <th scope="row">11:00 AM - 11:30 AM</th> <td>Talk 4 [Topic: TBD]</td> </tr>
                    <tr> <th scope="row">11:30 AM - Noon</th>     <td>Talk 5 [Topic: TBD]</td> </tr>
                    <tr> <th scope="row">Noon - 12:30 PM</th>     <td>Talk 6 [Topic: TBD]</td> </tr>
                    <tr> <th scope="row">12:30 AM - 13:00 PM</th> <td>Talk 7 [Topic: TBD]</td> </tr>
                  </tbody>
                </table>
            </div>
        </div>

        <div class="content-container container">
            <div class="header"><h4>Speakers</h4></div>
            <div class="main speakers-list">
                <div class="row">
                    <div class="col-l col-md-12 col-lg-2">
                        <img src="static/speakers/singh.jpg" />
                    </div>
                    <div class="col-r col-md-12 col-lg-10">
                        <p><b>Rishabh Singh</b> is a research scientist in the Google Brain team, which works on developing new deep learning architectures for learning programs and program analysis.
                        Singh develop new program synthesis techniques for helping end-users, students, and programmers. Apart from research, he enjoy playing bridge.</p>
                    </div>
                </div>
            </div>
        </div>

        <div class="content-container container">
            <div class="header"><h4>Organizers</h4></div>
            <div class="main organizers-list">
                <div class="d-flex m-auto">
                    <div class="item">
                        <img src="static/organizers/mao.jpg" width="150px" />
                        <p><b>Jiayuan Mao</b><br/>(MIT)</p>
                    </div>
                    <div class="item">
                        <img src="static/organizers/ellis.jpg" width="150px" />
                        <p><b>Kevin Ellis</b><br/>(MIT)</p>
                    </div>
                    <div class="item">
                        <img src="static/organizers/gan.jpg" width="150px" />
                        <p><b>Chuang Gan</b><br/>(MIT-IBM Watson AI Lab)</p>
                    </div>
                    <div class="item">
                        <img src="static/organizers/wu.jpg" width="150px" />
                        <p><b>Jiajun Wu</b><br/>(Stanford)</p>
                    </div>
                    <div class="item">
                        <img src="static/organizers/gutfreund.jpg" width="150px" />
                        <p><b>Dan Gutfreund</b><br/>(MIT-IBM Watson AI Lab)</p>
                    </div>
                    <div class="item">
                        <img src="static/organizers/tenenbaum.jpg" width="150px" />
                        <p><b>Josh Tenenbaum</b><br/>(MIT)</p>
                    </div>
                </div>
            </div>
        </div>

        <div class="content-container container">
            <div class="header"><h4>References</h4></div>
            <div class="main reference-list">
<div class="d-flex"><div class="number">[1]</div> <div>Ben Deen, Hilary Richardson, Daniel D. Dilks, Atsushi Takahashi, Boris Keil, Lawrence L. Wald, Nancy Kanwisher, and Rebecca Saxe. Organization of high-level visual cortex in human infants. Nature communications,8(1):1–10, 2017.</div></div>
<div class="d-flex"><div class="number">[2]</div> <div>Xuguang Duan, Qi Wu, Chuang Gan, Zhang Yiwei, Wenbing Huang, and Wenwu Zhu. Watch, reason and code: Learning to represent videos using program. In <i>ACM Multimedia</i>, 2019.</div></div>
<div class="d-flex"><div class="number">[3]</div> <div>Kevin Ellis, Maxwell Nye, Yewen Pu, Felix Sosa, Joshua B. Tenenbaum, and Armando Solar-Lezama. Write, execute, assess: Program  synthesis with a RERL. In <i>NeurIPS</i>, 2019</div></div>
<div class="d-flex"><div class="number">[4]</div> <div>Kevin Ellis, Daniel Ritchie, Armando Solar-Lezama, and Joshua B. Tenenbaum. Learning to infer graphics programs from hand-drawn images.  In <i>NeurIPS</i>, 2018.</div></div>
<div class="d-flex"><div class="number">[5]</div> <div>Chuang Gan, Yandong Li, Haoxiang Li, Chen Sun, and Boqing Gong. VQS: Linking segmentations to questions and answers for supervised attention in VQA and question-focused semantic segmentation. In <i>ICCV</i>, 2017.</div></div>
<div class="d-flex"><div class="number">[6]</div> <div>Chi Han, Jiayuan Mao, Chuang Gan, Joshua B. Tenenbaum, and Jiajun Wu. Visual concept metaconcept learner. In <i>NeurIPS</i>, 2019.</div></div>
<div class="d-flex"><div class="number">[7]</div> <div>Yunzhu Li, Jiajun Wu, Russ Tedrake, Joshua B. Tenenbaum, and Antonio Torralba. Learning particle dynamics for manipulating rigid bodies, deformable objects, and fluids. In <i>ICLR</i>, 2019.</div></div>
<div class="d-flex"><div class="number">[8]</div> <div>Yunzhu Li, Jiajun Wu, Jun-Yan Zhu, Joshua B. Tenenbaum, Antonio Torralba, and Russ Tedrake. Propagation networks for model-based controlunder partial observation. In <i>ICRA</i>, 2019.</div></div>
<div class="d-flex"><div class="number">[9]</div> <div>Yunchao Liu, Zheng Wu, Daniel Ritchie, William T. Freeman, Joshua B Tenenbaum, and Jiajun Wu. Learning to describe scenes with programs. In <i>ICLR</i>, 2019.</div></div>
<div class="d-flex"><div class="number">[10]</div> <div>Jiayuan Mao, Chuang Gan, Pushmeet Kohli, Joshua B. Tenenbaum, and Jiajun Wu. The neuro-symbolic concept learner: Interpreting scenes, words, and sentences from natural supervision. In <i>ICLR</i>, 2019.</div></div>
<div class="d-flex"><div class="number">[11]</div> <div>Jiayuan Mao, Xiuming Zhang, William T. Freeman, Joshua B. Tenenbaum,and Jiajun Wu. Program-guided image manipulators. In <i>ICCV</i>, 2019.</div></div>
<div class="d-flex"><div class="number">[12]</div> <div>Elizabeth S. Spelke and Katherine D. Kinzler. Core knowledge. Developmental Science, 10(1):89–96, 2007.</div></div>
<div class="d-flex"><div class="number">[13]</div> <div>Yonglong Tian, Andrew Luo, Xingyuan Sun, Kevin Ellis, William T. Free-man, Joshua B. Tenenbaum, and Jiajun Wu. Learning to infer and execute3d shape programs. In <i>ICLR</i>, 2019.</div></div>
<div class="d-flex"><div class="number">[14]</div> <div>Hao Wu, Jiayuan Mao, Yufeng Zhang, Yuning Jiang, Lei Li, Weiwei Sun, and Wei-Ying Ma. Unified visual-semantic embeddings: Bridging vision and language with structured meaning representations. In <i>CVPR</i>, 2019.</div></div>
<div class="d-flex"><div class="number">[15]</div> <div>Kexin Yi, Jiajun Wu, Chuang Gan, Antonio Torralba, Pushmeet Kohli, and Joshua B. Tenenbaum. Neural-symbolic VQA: Disentangling reasoning from vision and language understanding. In <i>NeurIPS</i>, 2018.</div></div>
            </div>
        </div>

    </div>
    <div id="footer">
        <p>The Tutorial Organiziers &copy; 2020</p>
    </div>
</div>

<!-- jQuery first, then Tether, then Bootstrap JS. -->
<script src="https://code.jquery.com/jquery-3.1.1.min.js" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/tether/1.4.0/js/tether.min.js"
        integrity="sha384-DztdAPBWPRXSA/3eYEEUWrWCy7G5KFbe8fFjk5JAIxUYHKkDx6Qin1DkWx51bBrb" crossorigin="anonymous"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-alpha.6/js/bootstrap.min.js"
        integrity="sha384-vBWWzlZJ8ea9aCX4pEW3rVHjgjt7zpkNpZk+02D9phzyeVkE+jo0ieGizqPLForn" crossorigin="anonymous"></script>
<script type="text/javascript" src="static/js/jquery.color.min.js"></script>
<script type="text/javascript" src="static/js/wave.js"></script>
</body>
</html>
